{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VenGr0/Convolutional_NN/blob/main/%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%9618.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lk_gQKeMC2A"
      },
      "outputs": [],
      "source": [
        "from keras.applications import MobileNet\n",
        "from keras import models\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "def model_maker():\n",
        "    base_model = MobileNet(include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    custom_model = base_model(input)\n",
        "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
        "    custom_model = Dense(64, activation='relu')(custom_model)\n",
        "    custom_model = Dropout(0.5)(custom_model)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
        "\n",
        "    return Model(inputs=input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_maker.summary()"
      ],
      "metadata": {
        "id": "HhSQ9KCTe7Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import MobileNet\n",
        "from keras import models\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "\n",
        "NUM_CLASSES=2\n",
        "\n",
        "def model_maker():\n",
        "    base_model = MobileNet(include_top=False, input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    custom_model = base_model(input)\n",
        "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
        "    custom_model = Dense(64, activation='relu')(custom_model)\n",
        "    custom_model = Dropout(0.5)(custom_model)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
        "\n",
        "    return Model(inputs=input, outputs=predictions)"
      ],
      "metadata": {
        "id": "Ag57SJBaWI-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal = model_maker()\n",
        "animal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mVndZBejJj5",
        "outputId": "6fd4dd97-f57a-4d74-97c1-5fefd062ed5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.functional.Functional at 0x7d88f60256c0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/academy.ai/cat-and-dog.zip\n",
        "# Разархивируем датасета во временную папку 'temp'\n",
        "!unzip -qo \"cat-and-dog\" -d ./temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UupMgTUvjXqn",
        "outputId": "7d0d2d7d-fdf4-42fc-d3e2-4280589e1ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-14 14:42:05--  https://storage.yandexcloud.net/academy.ai/cat-and-dog.zip\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228082266 (218M) [application/x-zip-compressed]\n",
            "Saving to: ‘cat-and-dog.zip’\n",
            "\n",
            "cat-and-dog.zip     100%[===================>] 217.52M  19.6MB/s    in 12s     \n",
            "\n",
            "2024-05-14 14:42:18 (17.9 MB/s) - ‘cat-and-dog.zip’ saved [228082266/228082266]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import shutil\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Папка с сортировкой по категориям\n",
        "IMAGE_PATH = './temp/training_set/training_set/'\n",
        "\n",
        "# Папка с выборками\n",
        "BASE_DIR = './dataset/'\n",
        "\n",
        "# Определение списка имен классов\n",
        "CLASS_LIST = sorted(os.listdir(IMAGE_PATH))\n",
        "\n",
        "# Определение количества классов\n",
        "CLASS_COUNT = len(CLASS_LIST)\n",
        "\n",
        "IMAGE_PATH_1 = './temp/test_set/test_set/'\n",
        "\n",
        "# При повторном запуске пересоздаим структуру каталогов\n",
        "# Если папка существует, то удаляем ее со всеми вложенными каталогами и файлами\n",
        "if os.path.exists(BASE_DIR):\n",
        "    shutil.rmtree(BASE_DIR)\n",
        "\n",
        "# Создание папки BASE_DIR\n",
        "os.mkdir(BASE_DIR)\n",
        "\n",
        "# Сцепляем путь до папки с именем вложенной папки. Аналогично BASE_DIR + '/train'\n",
        "train_dir = os.path.join(BASE_DIR, 'train')\n",
        "\n",
        "# Создаем подпапку, используя путь\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# Сцепляем путь до папки с именем вложенной папки. Аналогично BASE_DIR + '/validation'\n",
        "validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "# Создаем подпапку, используя путь\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "# Сцепляем путь до папки с именем вложенной папки. Аналогично BASE_DIR + '/test'\n",
        "test_dir = os.path.join(BASE_DIR, 'test')\n",
        "\n",
        "# Создаем подпапку, используя путь\n",
        "os.mkdir(test_dir)"
      ],
      "metadata": {
        "id": "lk88e0n7jywD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_names = sorted(list(os.listdir('/content/temp')))\n",
        "dir_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VagHmEmUnXja",
        "outputId": "ebe9dbcb-92e4-43c4-df48-774461336e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_set', 'training_set']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_files = []\n",
        "tr_files = []\n",
        "\n",
        "for i in dir_names:\n",
        "  for dirpath, dirs, filenames in os.walk('/content/temp'+'/'+i):\n",
        "    for filename in filenames:\n",
        "      if i==dir_names[0]:\n",
        "        test_files.append(os.path.join(dirpath, filename))\n",
        "      if i==dir_names[1]:\n",
        "        tr_files.append(os.path.join(dirpath, filename))\n",
        "\n",
        "print(len(tr_files))\n",
        "print(len(test_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGZS5tmSndCY",
        "outputId": "40ccb9b6-e664-42fe-e544-c97cc5c2c037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8005\n",
            "2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(\n",
        "    img_path: str,\n",
        "    new_path: str,\n",
        "    class_name: str,\n",
        "    start_index: int,\n",
        "    end_index: int):\n",
        "\n",
        "    src_path = os.path.join(img_path, class_name)  # Полный путь к папке с изображениями класса\n",
        "    dst_path = os.path.join(new_path, class_name)  # Полный путь к папке с новым датасетом класса\n",
        "\n",
        "    # Получение списка имен файлов с изображениями текущего класса\n",
        "    class_files = os.listdir(src_path)\n",
        "\n",
        "    # Создаем подпапку, используя путь\n",
        "    os.mkdir(dst_path)\n",
        "\n",
        "    for fname in class_files[start_index : end_index]:\n",
        "        src = os.path.join(src_path, fname)\n",
        "        dst = os.path.join(dst_path, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "for class_label in range(CLASS_COUNT):    # Перебор по всем классам по порядку номеров (их меток)\n",
        "    class_name = CLASS_LIST[class_label]  # Выборка имени класса из списка имен\n",
        "\n",
        "    create_dataset(IMAGE_PATH, train_dir, class_name, 0, 3000)\n",
        "    create_dataset(IMAGE_PATH, validation_dir, class_name, 3000, 4000)\n",
        "    create_dataset(IMAGE_PATH_1, test_dir, class_name, 0, 2023)"
      ],
      "metadata": {
        "id": "rJ9G7tKpqdvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Аугментация изображений\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Загрузка предобученной модели\n",
        "base_model = MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "# Добавление новых слоев\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Компиляция модели\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)\n",
        "\n",
        "# Проверка модели на тестовой выборке\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3ZXYwidqteX",
        "outputId": "2e63b755-8243-416f-dfeb-ed234bdf969a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "<ipython-input-9-ad3030aa64c2>:51: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 59s 560ms/step - loss: 0.5971 - accuracy: 0.8675 - val_loss: 0.1818 - val_accuracy: 0.9480\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 63s 627ms/step - loss: 0.2306 - accuracy: 0.9135 - val_loss: 0.1249 - val_accuracy: 0.9540\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 61s 608ms/step - loss: 0.1908 - accuracy: 0.9295 - val_loss: 0.1878 - val_accuracy: 0.9340\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 55s 553ms/step - loss: 0.1800 - accuracy: 0.9315 - val_loss: 0.1037 - val_accuracy: 0.9620\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 61s 615ms/step - loss: 0.1614 - accuracy: 0.9395 - val_loss: 0.0861 - val_accuracy: 0.9660\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 55s 548ms/step - loss: 0.1684 - accuracy: 0.9315 - val_loss: 0.1063 - val_accuracy: 0.9650\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 61s 611ms/step - loss: 0.1358 - accuracy: 0.9485 - val_loss: 0.1113 - val_accuracy: 0.9580\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 54s 534ms/step - loss: 0.1507 - accuracy: 0.9345 - val_loss: 0.1846 - val_accuracy: 0.9510\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 55s 549ms/step - loss: 0.1464 - accuracy: 0.9485 - val_loss: 0.0984 - val_accuracy: 0.9640\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 54s 544ms/step - loss: 0.1445 - accuracy: 0.9490 - val_loss: 0.0711 - val_accuracy: 0.9680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-ad3030aa64c2>:59: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test acc: 0.9819999933242798\n"
          ]
        }
      ]
    }
  ]
}